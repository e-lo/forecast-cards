{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForecastCards.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DxV3ghbzkaHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "try:\n",
        "  import goodtables\n",
        "except:\n",
        "  !pip install goodtables\n",
        "  import goodtables\n",
        "try:\n",
        "  import tableschema\n",
        "except:\n",
        "  !pip install tableschema\n",
        "  import tableschema\n",
        "try:\n",
        "  import tableschema_pandas\n",
        "except:\n",
        "  !pip install tableschema_pandas\n",
        "  import tableschema_pandas\n",
        "try:\n",
        "  import graphviz\n",
        "except:\n",
        "  !pip install graphviz\n",
        "  !apt-get install graphviz\n",
        "  import graphviz\n",
        "from tableschema import Schema\n",
        "#!apt-get install graphviz\n",
        "# NOTE: must restart kernal after doing this\n",
        "\n",
        "try:\n",
        "  import statsmodels\n",
        "except:\n",
        "  !pip install statsmodels\n",
        "  import statsmodels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLtt3HDd2j8Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Validate your data against data schemas\n",
        "\n",
        " 1. find and validate schemas themselves\n",
        " 2. find and validate data"
      ]
    },
    {
      "metadata": {
        "id": "Ck4yYehAFzsa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clean your JSON with https://jsonlint.com/\n",
        "Check against schemas with https://try.goodtables.io/"
      ]
    },
    {
      "metadata": {
        "id": "IBXZafrNkkyg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GITHUB_USER  = \"e-lo\"\n",
        "GITHUB_REPO  = \"forecast-cards\"\n",
        "BRANCH       = \"master\"\n",
        "SHA          = \"f35185168b238429157adcbf5ba09d09ae7d0172\"\n",
        "SUBDIRS      = [\"examples\"] #specify at least one\n",
        "repo_api = \"\".join([\"https://api.github.com/repos/\",GITHUB_USER,\"/\",GITHUB_REPO,\"/git/trees/\",SHA,\"?recursive=1\"])\n",
        "repo_raw = \"\".join([\"https://raw.github.com/\",GITHUB_USER,\"/\",GITHUB_REPO,\"/\",BRANCH,\"/\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdmqf-IXJFPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Find and validate **schema**s"
      ]
    },
    {
      "metadata": {
        "id": "AQsGv03g947A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## specify which schemas to use\n",
        "schemas_loc = {\n",
        "    \"poi\": urljoin(repo_raw,\"poi-schema.json\"),\n",
        "    \"scenario\": urljoin(repo_raw,\"scenario-schema.json\"),\n",
        "    \"project\": urljoin(repo_raw,\"project-schema.json\"),\n",
        "    \"observations\": urljoin(repo_raw,\"observations-schema.json\"),\n",
        "    \"forecast\": urljoin(repo_raw,\"forecast-schema.json\"),\n",
        "}\n",
        "\n",
        "## Confirm Schemas are valid\n",
        "schemas = {}\n",
        "for k,v in schemas_loc.items():\n",
        "  print (\"Obtaining \", k,\"schema from: \",v)\n",
        "  schemas[k] = Schema(v)\n",
        "#requests.get(v)\n",
        "#print(schemas['poi'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2IziWzuVlfZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "erd_graph = Digraph(name='Schemas', node_attr={'shape': 'plain'})\n",
        "\n",
        "\n",
        "for k,v in schemas.items():\n",
        "  node_label=\"<<table border='0' cellborder='1' cellspacing='0'>\"\n",
        "  node_label+=\"<tr><td><b>\"\n",
        "  node_label+=str(k)\n",
        "  node_label+=\"</b></td></tr>\"\n",
        "  for f in v.descriptor['fields']:\n",
        "    node_label+=\"<tr><td port='\"\n",
        "    node_label+=f['name']\n",
        "    node_label+=\"'>\"\n",
        "    node_label+=f['name']\n",
        "    node_label+=\"</td></tr>\"\n",
        "  node_label+=\"</table>>\"\n",
        "  erd_graph.node(k,label = node_label)\n",
        "\n",
        "erd_graph.edge(\"poi:poi_id\", \"observations:poi_id\")\n",
        "erd_graph.edge(\"observations:forecast_id\",\"forecast:forecast_id\")\n",
        "erd_graph.edge(\"scenario:run_id\",\"forecast:run_id\")\n",
        "erd_graph.edge(\"project:project_id\",\"scenario:project_id\")\n",
        "\n",
        "erd_graph \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tx7fM88DJbGU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Locate Data"
      ]
    },
    {
      "metadata": {
        "id": "ZLcVSeZaZ8Oz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "r = requests.get(repo_api)\n",
        "rj = r.json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UO7BVZj4ZpSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "card_locs = {\n",
        "           \"poi\": [],\n",
        "           \"scenario\": [],\n",
        "           \"project\": [],\n",
        "           \"observations\": [],\n",
        "           \"forecast\": [],\n",
        "    }\n",
        "\n",
        "## todo better regex matching by project\n",
        "for file in rj['tree']:\n",
        "  path_list = file['path'].split(\"/\")\n",
        "  \n",
        "  if len(path_list)>2 and path_list[0] in SUBDIRS and file['type']=='blob':\n",
        "      if path_list[-1][0:8].lower()==\"forecast\":\n",
        "          full_url = urljoin(repo_raw,file['path'])\n",
        "          print(\"adding\",full_url,\"to forecast\")\n",
        "          card_locs[\"forecast\"].append(full_url)\n",
        "      if path_list[-1][0:12].lower()==\"observations\":\n",
        "          full_url = urljoin(repo_raw,file['path'])\n",
        "          print(\"adding\",full_url,\"to observations\")\n",
        "          card_locs[\"observations\"].append(full_url)\n",
        "      if path_list[-1][0:3].lower()==\"poi\":\n",
        "          full_url = urljoin(repo_raw,file['path'])\n",
        "          print(\"adding\",full_url,\"to poi\")\n",
        "          card_locs[\"poi\"].append(full_url)          \n",
        "      if path_list[-1][0:7].lower()==\"project\":\n",
        "          full_url = urljoin(repo_raw,file['path'])\n",
        "          print(\"adding\",full_url,\"to project\")\n",
        "          card_locs[\"project\"].append(full_url)     \n",
        "      if path_list[-1][0:8].lower()==\"scenario\":\n",
        "          full_url = urljoin(repo_raw,file['path'])\n",
        "          print(\"adding\",full_url,\"to scenario\")\n",
        "          card_locs[\"scenario\"].append(full_url)   \n",
        "                    \n",
        "#card_locs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfLByW--_qtB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validate Data Tables\n",
        "\n",
        "If errors found, try https://try.goodtables.io as a good GUI for identifying issues."
      ]
    },
    {
      "metadata": {
        "id": "xydLF5dMacMS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from goodtables import validate\n",
        "reports={}\n",
        "for k,v in card_locs.items():\n",
        "  #print (\"validating\",k,v)\n",
        "  reports[k] = validate(card_locs[k][0],schema=requests.get(schemas_loc[k]).json())\n",
        "  if not reports[k]['valid']: \n",
        "    print (\"--->INVALID TABLE\", k)\n",
        "    reports[k]\n",
        "  else:\n",
        "    print (\"--->VALID\",k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyoFV5Z4BZKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reports['scenario']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zxIQ5BIquOaB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Estimation File\n",
        "\n",
        "1. Merge tables on keys\n",
        "2. Clean unusable records based on required variables\n",
        "3. Create categorical variables and then dummy variables\n",
        "4. Scale variables by forecast_value\n",
        "\n",
        "\n",
        "## Merge tables\n"
      ]
    },
    {
      "metadata": {
        "id": "y0JsXNXbsFLQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "project_df = pd.concat([pd.read_csv(f, parse_dates=['year_open_planned','year_horizon','date_open_actual'],infer_datetime_format=True) for f in card_locs[\"project\"]], ignore_index=True)\n",
        "scenario_df = pd.concat([pd.read_csv(f, parse_dates=['forecast_creation_date','scenario_date'],infer_datetime_format=True) for f in card_locs[\"scenario\"]], ignore_index=True)\n",
        "scenario_proj_df = scenario_df.merge(project_df, on='project_id', how='left')\n",
        "\n",
        "poi_df = pd.concat([pd.read_csv(f) for f in card_locs[\"poi\"]], ignore_index=True)\n",
        "observations_df = pd.concat([pd.read_csv(f, dtype={'obs_value':float}) for f in card_locs[\"observations\"]], ignore_index=True)\n",
        "observations_poi_df = observations_df.merge(poi_df, on='poi_id', how='left')\n",
        "\n",
        "forecast_df = pd.concat([pd.read_csv(f, dtype={'forecast_value':float}) for f in card_locs[\"forecast\"]], ignore_index=True)\n",
        "\n",
        "all_df = forecast_df.merge(observations_poi_df, on='forecast_match_id', how='left').merge(scenario_proj_df, on='run_id', how='left')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "My4aMxPRpYaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QqJbBXJouNWq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clean Dataset\n",
        "\n",
        "Only keep records that don't have NULL for required variables"
      ]
    },
    {
      "metadata": {
        "id": "5SbApzSBxSlC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "REQUIRED_VARS = ['scenario_date','forecast_system_type','forecast_creation_date','forecast_value','forecast_value','obs_value', 'area_type', 'facility_type','state','project_type']\n",
        "usable_df= all_df.dropna(subset=REQUIRED_VARS)\n",
        "print(\"Kept\",len(usable_df),\"of\",len(all_df))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xz4SbQWPCJSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create categorical variables\n",
        "\n",
        "1. Decade for forecast creation and scenario\n",
        "2. Large projects"
      ]
    },
    {
      "metadata": {
        "id": "HLZF0ala1gOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## categorical decades variable\n",
        "usable_df['creation_decade'] = (usable_df['forecast_creation_date'].apply(lambda x: x.year//10*10)).astype('category')\n",
        "usable_df['scenario_decade'] = (usable_df['scenario_date'].apply(lambda x: x.year//10*10)).astype('category')\n",
        "\n",
        "## large projects dummy variable\n",
        "breakpoint = 30000\n",
        "bins = [usable_df['forecast_value'].min(), breakpoint, breakpoint+usable_df['forecast_value'].max()]\n",
        "labels = [\"small_project\",\"large_project\"]\n",
        "usable_df['project_size'] = pd.cut(usable_df['forecast_value'], bins=bins, labels=labels)\n",
        "#usable_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19OWlL6rCY6E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Turn categorical variables into dummy variables"
      ]
    },
    {
      "metadata": {
        "id": "DeyRPKhYwZj_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "categorical_cols = ['project_size','creation_decade','scenario_decade','functional_class','forecast_system_type','project_type','agency','forecaster_type','area_type','facility_type','state']\n",
        "dummy_df = pd.get_dummies(usable_df[categorical_cols])\n",
        "usable_dummy_df = pd.concat([usable_df[[v for v in REQUIRED_VARS if v not in categorical_cols]],dummy_df],axis=1)\n",
        "usable_dummy_df.columns\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQ4OF4SRCmP6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Scale variables\n",
        "By `forecast value`"
      ]
    },
    {
      "metadata": {
        "id": "kCcsv2VPzmTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#usable_dummy_df \n",
        "##TODO, not currently working\n",
        "scaled_df = usable_dummy_df.mul(usable_dummy_df['forecast_value'], axis=0)\n",
        "#scaled_df \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFimfUa-rGHJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Estimate Quantiles\n",
        "\n",
        "With understanding that GDE noted that this package doesn't work right...\n",
        "\n",
        "Start with OLS to see if example data is OK"
      ]
    },
    {
      "metadata": {
        "id": "VtF4bBpNryc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lm = smf.ols('obs_value ~ forecast_value', data=usable_df).fit()\n",
        "\n",
        "print (lm.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WWH4s1WoUe0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(res.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}